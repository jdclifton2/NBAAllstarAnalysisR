---
title: "Predicting NBA Allstars"
author: "Mohammed Bukhattala, Justin Clifton, Maxwell Pitney, Graham Swain"
date: "4/24/2021"
abstract: "The most prized individual accolade for a player in the NBA is the Most Valuable Player award. Winning this award signifies that coaches, the media, and former players thought that the winner was the most important player in the NBA. There have been 65 different players who have won the NBA mvp. These players played different positions, had different statistics, and come from different eras. What then, do they have in common? We offer several models that attempt to predict the NBA MVP given player season statistics such as points, blocks, etc."
output: html_document
---

Models that did not work: QDA, Logistic.
```{r}
library(readr)
library(tibble)
library(ggplot2)
#library(GGally)
library(dplyr)
set.seed(23)
DF = read.csv("NBA_Stats_MVP.csv", header = TRUE)
nba_df = na.omit(DF)
names(nba_df)
nba_df$was_mvp = as.logical(nba_df$was_mvp)
nbaTib = as_tibble(nba_df)
cleanDF = select(nbaTib, -c(Pos, Tm, Name, Year, is_allstar))

# ggplot(nbaTib, aes(x = factor(is_allstar), fill = is_allstar)) +
#     geom_bar()
```


```{r}
ggplot(data = nbaTib) +
  geom_point(mapping = aes(x = FGA, y = FG, color = was_mvp, shape=was_mvp))
```


```{r}
ggplot(filter(DF, was_mvp == 1), aes(x = factor(Pos), fill = Pos)) +
    geom_bar() +
    scale_y_continuous(breaks=c(4,6,8,10,12)) +
    labs(title="NBA MVPS by Position (1974 - 2017)",
        x ="Position", y = "frequency")
```
```{r}
ggplot(filter(nbaTib, was_mvp == 1), aes(x = Pos, fill = Pos)) +
    geom_bar() +
    scale_y_continuous(breaks=c(4,6,8,10)) +
    labs(title="NBA MVPS by Position (1983 - 2017)",
        x ="Position", y = "frequency")
```


# Modeling

First we split the data into training and testing.
```{r}
train = sample(dim(cleanDF)[1], dim(cleanDF)[1]/2)
test = cleanDF[-train, ]
```


The first model that we are going to fit will be an LDA model. It is important to remember that one of the assumptions of LDA is that none of the features are heavily correlated. We will first examine a correlation matrix of our data. 
```{r}
library(corrplot)
library(caret)
#trying to make correlation map
# library(reshape2)
# library(ggcorrplot)
# names(cleanDF)
corMat = cor(cleanDF)
corrplot(corMat, tl.cex=0.5,method="shade")

# as_tibble(cor[cor > 0.7])
# ggcorrplot(cor[cor > .7])
# ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) +
#   geom_tile()
```
It can be seen that there are many heavily correlated features. We will now drop some of these features. 

```{r}
names = findCorrelation(corMat, cutoff = .5, verbose = TRUE, names = TRUE)

nonCorDF = select(cleanDF, -all_of(names))

corMat2 = cor(nonCorDF)

corrplot(corMat2, tl.cex=0.5,method="shade")
```


Now that we have removed heavily correlated features, we will now perform lda.
```{r}
library(MASS)

truePositive <- function(table) {
  tp = table[2,2]
  tn = table[1,1]
  fp = table[1,2]
  fn = table[2,1]
  return(tp/(tp + fn))
}

falseNegative <- function(table) {
  tp = table[2,2]
  tn = table[1,1]
  fp = table[1,2]
  fn = table[2,1]
  return(fn/(tp + fn))
}

f1Score <- function(table) {
  tp = table[2,2]
  tn = table[1,1]
  fp = table[1,2]
  fn = table[2,1]
  return(2*tp/(2 * tp + fp + fn))
}

trainNonCor = sample(dim(nonCorDF)[1], dim(nonCorDF)[1]/2)
testNonCor = nonCorDF[-train, ]
ldaFit = lda(was_mvp~., data = nonCorDF, subset=train)
ldaPred = predict(ldaFit, testNonCor)
ldaTable = table(ldaPred$class,testNonCor$was_mvp)
ldaTable
mean(ldaPred$class == testNonCor$was_mvp)
truePositive(ldaTable)
falseNegative(ldaTable)
f1Score(ldaTable)
```
In the context of our problem, a true positive happens when a player was predicted as the MVP, and actually won the MVP. A true negative happens when a player was predicted as a non-MVP and was not the MVP. A false positive occurs when a player was predicted as the MVP but did not win the MVP. A false negative occurs when a player was predicted as a non-MVP but actually won the MVP. For this model, the overall accuracy is very high at $99.28699\%$. The model correctly predicted the MVP $81.81818\%$ of the time. At the same time, the model predicted a non-MVP as the MVP $0.6601568\%$ of the time.

```{r}
# qdaFit = qda(was_mvp~., data = cleanDF, subset = train)
# pred = predict(qdaFit, test)
# table(pred$class, test$was_mvp)
# mean(pred$class == test$was_mvp)
```





